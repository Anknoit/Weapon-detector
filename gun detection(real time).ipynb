{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gun Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "guns detected\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import imutils\n",
    "import datetime\n",
    "\n",
    "gun_cascade = cv2.CascadeClassifier('cascade_gun.xml')\n",
    "camera = cv2.VideoCapture('data/gun4_2.mp4')\n",
    "# initialize the first frame in the video stream\n",
    "firstFrame = None\n",
    "\n",
    "# loop over the frames of the video\n",
    "\n",
    "gun_exist = False\n",
    "\n",
    "while True:\n",
    "    (grabbed, frame) = camera.read()\n",
    "\n",
    "    # if the frame could not be grabbed, then we have reached the end of the video\n",
    "    if not grabbed:\n",
    "        break\n",
    "\n",
    "    # resize the frame, convert it to grayscale, and blur it\n",
    "    frame = imutils.resize(frame, width=500)\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.GaussianBlur(gray, (21, 21), 0)\n",
    "    \n",
    "    gun = gun_cascade.detectMultiScale(gray, 1.3, 5, minSize = (100, 100))\n",
    "    \n",
    "    if len(gun) > 0:\n",
    "        gun_exist = True\n",
    "        \n",
    "    for (x,y,w,h) in gun:\n",
    "        frame = cv2.rectangle(frame,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "        roi_gray = gray[y:y+h, x:x+w]\n",
    "        roi_color = frame[y:y+h, x:x+w]    \n",
    "\n",
    "    # if the first frame is None, initialize it\n",
    "    if firstFrame is None:\n",
    "        firstFrame = gray\n",
    "        continue\n",
    "\n",
    "    # draw the text and timestamp on the frame\n",
    "    cv2.putText(frame, datetime.datetime.now().strftime(\"%A %d %B %Y %I:%M:%S%p\"),\n",
    "                    (10, frame.shape[0] - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.35, (0, 0, 255), 1)\n",
    "\n",
    "    # show the frame and record if the user presses a key\n",
    "    cv2.imshow(\"Security Feed\", frame)\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "if gun_exist:\n",
    "    print(\"guns detected\")\n",
    "else:\n",
    "    print(\"guns NOT detected\")\n",
    "\n",
    "# cleanup the camera and close any open windows\n",
    "camera.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Knife Detection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loading YOLO model for knife: best.pt\n",
      "[INFO] YOLO device: cpu\n",
      "[INFO] Loading Haar cascade for gun: cascade_gun.xml\n",
      "[INFO] Starting detection. Press 'q' to quit.\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Combined detector:\n",
    " - Knife: Ultralytics YOLO .pt model\n",
    " - Gun: OpenCV Haar cascade XML\n",
    "\n",
    "Usage:\n",
    "  python detect_gun_knife.py --source 0                    # webcam\n",
    "  python detect_gun_knife.py --source video.mp4            # local video\n",
    "  python detect_gun_knife.py --source rtsp://...           # RTSP stream\n",
    "\"\"\"\n",
    "\n",
    "import argparse\n",
    "import time\n",
    "import cv2\n",
    "import imutils\n",
    "from ultralytics import YOLO\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# ----------------------------\n",
    "# Arguments\n",
    "# ----------------------------\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--knife-model\", type=str, default=\"best.pt\", help=\"Path to YOLO .pt for knife\")\n",
    "parser.add_argument(\"--gun-cascade\", type=str, default=\"cascade_gun.xml\", help=\"Path to gun Haar cascade XML\")\n",
    "# parser.add_argument(\"--source\", type=str, default=\"data/gun4_2.mp4\", help=\"Video source (0 for webcam or path/rtsp)\")\n",
    "parser.add_argument(\"--source\", type=str, default=\"data/knife_test_video.mp4\", help=\"Video source (0 for webcam or path/rtsp)\")\n",
    "\n",
    "parser.add_argument(\"--conf\", type=float, default=0.35, help=\"YOLO confidence threshold\")\n",
    "parser.add_argument(\"--save\", action=\"store_true\", help=\"Save output video to output.mp4\")\n",
    "parser.add_argument(\"--device\", type=str, default=None, help=\"Device for YOLO, e.g. 'cpu' or 'cuda:0' (auto if None)\")\n",
    "# args = parser.parse_args() # Comment it out when using in jupyter\n",
    "args, unknown = parser.parse_known_args()\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# Load models\n",
    "# ----------------------------\n",
    "# YOLO knife model\n",
    "if not os.path.exists(args.knife_model):\n",
    "    raise SystemExit(f\"Knife model not found: {args.knife_model}\")\n",
    "print(\"[INFO] Loading YOLO model for knife:\", args.knife_model)\n",
    "yolo_device = args.device if args.device else (\"cuda:0\" if __import__(\"torch\").cuda.is_available() else \"cpu\")\n",
    "model = YOLO(args.knife_model)\n",
    "# move model to device if required by ultralytics API (model(..., device=...))\n",
    "print(f\"[INFO] YOLO device: {yolo_device}\")\n",
    "\n",
    "# Haar cascade for gun\n",
    "if not os.path.exists(args.gun_cascade):\n",
    "    raise SystemExit(f\"Gun cascade not found: {args.gun_cascade}\")\n",
    "print(\"[INFO] Loading Haar cascade for gun:\", args.gun_cascade)\n",
    "gun_cascade = cv2.CascadeClassifier(args.gun_cascade)\n",
    "\n",
    "# ----------------------------\n",
    "# Open video source\n",
    "# ----------------------------\n",
    "source = args.source\n",
    "if source.isdigit():\n",
    "    source = int(source)\n",
    "\n",
    "cap = cv2.VideoCapture(source)\n",
    "if not cap.isOpened():\n",
    "    raise SystemExit(f\"[ERROR] Cannot open source: {args.source}\")\n",
    "\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH) or 640)\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT) or 480)\n",
    "fps_in = cap.get(cv2.CAP_PROP_FPS) or 25.0\n",
    "\n",
    "writer = None\n",
    "if args.save:\n",
    "    fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "    writer = cv2.VideoWriter(\"output.mp4\", fourcc, fps_in, (width, height))\n",
    "    print(\"[INFO] Saving output to output.mp4\")\n",
    "\n",
    "# ----------------------------\n",
    "# Helper: draw box + label\n",
    "# ----------------------------\n",
    "def draw_label(frame, text, box, color=(0, 255, 0), thickness=2):\n",
    "    x1, y1, x2, y2 = box\n",
    "    cv2.rectangle(frame, (x1, y1), (x2, y2), color, thickness)\n",
    "    (tw, th), _ = cv2.getTextSize(text, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 1)\n",
    "    cv2.rectangle(frame, (x1, y1 - th - 6), (x1 + tw + 6, y1), color, -1)\n",
    "    cv2.putText(frame, text, (x1 + 3, y1 - 4), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 1, cv2.LINE_AA)\n",
    "\n",
    "# ----------------------------\n",
    "# Main loop\n",
    "# ----------------------------\n",
    "print(\"[INFO] Starting detection. Press 'q' to quit.\")\n",
    "prev_time = time.time()\n",
    "while True:\n",
    "    grabbed, frame = cap.read()\n",
    "    if not grabbed:\n",
    "        break\n",
    "\n",
    "    # optional resize for speed (keep aspect)\n",
    "    frame = imutils.resize(frame, width=800)\n",
    "\n",
    "    # ---- Haar gun detection (works on grayscale) ----\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    # tune scaleFactor and minNeighbors to reduce false positives\n",
    "    guns = gun_cascade.detectMultiScale(gray, scaleFactor=1.3, minNeighbors=5, minSize=(30, 30))\n",
    "\n",
    "    # draw gun boxes\n",
    "    for (x, y, w, h) in guns:\n",
    "        x2, y2 = x + w, y + h\n",
    "        draw_label(frame, \"GUN\", (x, y, x2, y2), color=(0, 0, 255))\n",
    "\n",
    "    # ---- YOLO knife detection ----\n",
    "    # Ultralytics accepts numpy array frames directly:\n",
    "    try:\n",
    "        # predict returns a Results object (list-like). Pass device and conf.\n",
    "        results = model.predict(source=[frame], conf=args.conf, device=yolo_device, verbose=False)\n",
    "        # results is a list; take first\n",
    "        if results and len(results) > 0:\n",
    "            r = results[0]\n",
    "            # r.boxes: xyxy, conf, cls\n",
    "            if hasattr(r, \"boxes\") and r.boxes is not None and len(r.boxes) > 0:\n",
    "                boxes = r.boxes.xyxy.cpu().numpy() if hasattr(r.boxes.xyxy, \"cpu\") else np.array(r.boxes.xyxy)\n",
    "                confs = r.boxes.conf.cpu().numpy() if hasattr(r.boxes.conf, \"cpu\") else np.array(r.boxes.conf)\n",
    "                clss = r.boxes.cls.cpu().numpy() if hasattr(r.boxes.cls, \"cpu\") else np.array(r.boxes.cls)\n",
    "                for box, conf, cls in zip(boxes, confs, clss):\n",
    "                    x1, y1, x2, y2 = map(int, box)\n",
    "                    label = r.names[int(cls)] if hasattr(r, \"names\") else (\"knife\" if int(cls)==0 else str(int(cls)))\n",
    "                    text = f\"{label} {conf:.2f}\"\n",
    "                    draw_label(frame, text, (x1, y1, x2, y2), color=(0, 255, 0))\n",
    "    except Exception as e:\n",
    "        # if YOLO fails for a frame, print once and continue\n",
    "        print(\"[WARN] YOLO exception:\", e)\n",
    "\n",
    "    # timestamp & FPS\n",
    "    now = time.time()\n",
    "    fps = 1.0 / (now - prev_time) if (now - prev_time) > 0 else 0.0\n",
    "    prev_time = now\n",
    "    ts = time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    cv2.putText(frame, f\"{ts}  FPS:{fps:.1f}\", (10, frame.shape[0] - 10),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.6, (200, 200, 200), 2)\n",
    "\n",
    "    # show & optionally write\n",
    "    cv2.imshow(\"Gun+Knife Detection\", frame)\n",
    "    if writer:\n",
    "        writer.write(frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "if writer:\n",
    "    writer.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loading YOLO model for knife: best.pt\n",
      "[INFO] YOLO device: cpu\n",
      "[INFO] Loading Haar cascade for gun: cascade_gun.xml\n",
      "[INFO] Starting detection. Press 'q' to quit.\n",
      "\n",
      "0: 384x640 (no detections), 102.8ms\n",
      "\n",
      "0: 384x640 (no detections), 115.3ms\n",
      "\n",
      "0: 384x640 (no detections), 105.7ms\n",
      "\n",
      "0: 384x640 (no detections), 88.3ms\n",
      "\n",
      "0: 384x640 (no detections), 105.6ms\n",
      "\n",
      "0: 384x640 (no detections), 141.1ms\n",
      "\n",
      "0: 384x640 1 knife, 94.4ms\n",
      "\n",
      "0: 384x640 (no detections), 86.0ms\n",
      "\n",
      "0: 384x640 (no detections), 106.8ms\n",
      "\n",
      "0: 384x640 (no detections), 123.3ms\n",
      "\n",
      "0: 384x640 (no detections), 108.2ms\n",
      "\n",
      "0: 384x640 (no detections), 124.2ms\n",
      "\n",
      "0: 384x640 (no detections), 101.6ms\n",
      "\n",
      "0: 384x640 (no detections), 101.7ms\n",
      "\n",
      "0: 384x640 1 guns, 97.7ms\n",
      "\n",
      "0: 384x640 2 gunss, 80.9ms\n",
      "\n",
      "0: 384x640 1 guns, 85.6ms\n",
      "\n",
      "0: 384x640 1 guns, 167.6ms\n",
      "\n",
      "0: 384x640 1 guns, 101.6ms\n",
      "\n",
      "0: 384x640 1 guns, 94.0ms\n",
      "\n",
      "0: 384x640 1 guns, 90.3ms\n",
      "\n",
      "0: 384x640 2 gunss, 81.5ms\n",
      "\n",
      "0: 384x640 2 gunss, 104.7ms\n",
      "\n",
      "0: 384x640 1 guns, 87.6ms\n",
      "\n",
      "0: 384x640 3 gunss, 70.4ms\n",
      "\n",
      "0: 384x640 2 gunss, 77.8ms\n",
      "\n",
      "0: 384x640 2 gunss, 75.7ms\n",
      "\n",
      "0: 384x640 (no detections), 70.8ms\n",
      "\n",
      "0: 384x640 2 gunss, 112.6ms\n",
      "\n",
      "0: 384x640 1 guns, 80.1ms\n",
      "\n",
      "0: 384x640 1 guns, 95.6ms\n",
      "\n",
      "0: 384x640 1 guns, 84.4ms\n",
      "\n",
      "0: 384x640 1 guns, 95.2ms\n",
      "\n",
      "0: 384x640 1 guns, 74.9ms\n",
      "\n",
      "0: 384x640 (no detections), 85.1ms\n",
      "\n",
      "0: 384x640 (no detections), 93.2ms\n",
      "\n",
      "0: 384x640 (no detections), 81.5ms\n",
      "\n",
      "0: 384x640 (no detections), 111.7ms\n",
      "\n",
      "0: 384x640 1 guns, 73.7ms\n",
      "\n",
      "0: 384x640 1 guns, 96.3ms\n",
      "\n",
      "0: 384x640 1 guns, 89.4ms\n",
      "\n",
      "0: 384x640 2 gunss, 76.1ms\n",
      "\n",
      "0: 384x640 1 guns, 97.7ms\n",
      "\n",
      "0: 384x640 1 guns, 71.8ms\n",
      "\n",
      "0: 384x640 1 guns, 73.9ms\n",
      "\n",
      "0: 384x640 1 guns, 83.1ms\n",
      "\n",
      "0: 384x640 2 gunss, 88.7ms\n",
      "\n",
      "0: 384x640 1 guns, 98.8ms\n",
      "\n",
      "0: 384x640 1 guns, 86.0ms\n",
      "\n",
      "0: 384x640 1 guns, 85.4ms\n",
      "\n",
      "0: 384x640 (no detections), 78.1ms\n",
      "\n",
      "0: 384x640 (no detections), 93.7ms\n",
      "\n",
      "0: 384x640 (no detections), 98.0ms\n",
      "\n",
      "0: 384x640 1 guns, 70.2ms\n",
      "\n",
      "0: 384x640 1 guns, 77.4ms\n",
      "\n",
      "0: 384x640 1 guns, 79.9ms\n",
      "\n",
      "0: 384x640 2 gunss, 112.3ms\n",
      "\n",
      "0: 384x640 1 guns, 70.5ms\n",
      "\n",
      "0: 384x640 2 gunss, 91.7ms\n",
      "\n",
      "0: 384x640 1 guns, 79.7ms\n",
      "\n",
      "0: 384x640 2 gunss, 73.9ms\n",
      "\n",
      "0: 384x640 2 gunss, 85.7ms\n",
      "\n",
      "0: 384x640 2 gunss, 93.9ms\n",
      "\n",
      "0: 384x640 2 gunss, 84.6ms\n",
      "\n",
      "0: 384x640 1 guns, 83.8ms\n",
      "\n",
      "0: 384x640 1 guns, 94.7ms\n",
      "\n",
      "0: 384x640 1 guns, 91.3ms\n",
      "\n",
      "0: 384x640 1 guns, 99.9ms\n",
      "\n",
      "0: 384x640 (no detections), 92.3ms\n",
      "\n",
      "0: 384x640 (no detections), 81.7ms\n",
      "\n",
      "0: 384x640 2 gunss, 109.7ms\n",
      "\n",
      "0: 384x640 1 guns, 100.3ms\n",
      "\n",
      "0: 384x640 1 guns, 91.6ms\n",
      "\n",
      "0: 384x640 1 guns, 85.8ms\n",
      "\n",
      "0: 384x640 (no detections), 72.8ms\n",
      "\n",
      "0: 384x640 (no detections), 105.5ms\n",
      "\n",
      "0: 384x640 (no detections), 70.5ms\n",
      "\n",
      "0: 384x640 1 guns, 95.4ms\n",
      "\n",
      "0: 384x640 1 guns, 80.4ms\n",
      "\n",
      "0: 384x640 1 guns, 105.1ms\n",
      "\n",
      "0: 384x640 1 guns, 87.8ms\n",
      "\n",
      "0: 384x640 1 guns, 80.5ms\n",
      "\n",
      "0: 384x640 1 guns, 79.6ms\n",
      "\n",
      "0: 384x640 1 guns, 105.2ms\n",
      "\n",
      "0: 384x640 (no detections), 71.1ms\n",
      "\n",
      "0: 384x640 (no detections), 75.5ms\n",
      "\n",
      "0: 384x640 1 guns, 77.3ms\n",
      "\n",
      "0: 384x640 (no detections), 83.0ms\n",
      "\n",
      "0: 384x640 (no detections), 81.9ms\n",
      "\n",
      "0: 384x640 1 guns, 70.6ms\n",
      "\n",
      "0: 384x640 1 guns, 69.3ms\n",
      "\n",
      "0: 384x640 1 guns, 82.8ms\n",
      "\n",
      "0: 384x640 2 gunss, 192.8ms\n",
      "\n",
      "0: 384x640 2 gunss, 76.8ms\n",
      "\n",
      "0: 384x640 2 gunss, 75.7ms\n",
      "\n",
      "0: 384x640 1 guns, 75.4ms\n",
      "\n",
      "0: 384x640 1 guns, 71.2ms\n",
      "\n",
      "0: 384x640 1 guns, 71.5ms\n",
      "\n",
      "0: 384x640 1 guns, 72.5ms\n",
      "\n",
      "0: 384x640 1 guns, 148.0ms\n",
      "\n",
      "0: 384x640 1 guns, 82.9ms\n",
      "\n",
      "0: 384x640 1 guns, 77.8ms\n",
      "\n",
      "0: 384x640 1 guns, 104.9ms\n",
      "\n",
      "0: 384x640 1 guns, 83.1ms\n",
      "\n",
      "0: 384x640 1 guns, 70.6ms\n",
      "\n",
      "0: 384x640 1 knife, 71.0ms\n",
      "\n",
      "0: 384x640 (no detections), 83.0ms\n",
      "\n",
      "0: 384x640 (no detections), 104.0ms\n",
      "\n",
      "0: 384x640 (no detections), 82.4ms\n",
      "\n",
      "0: 384x640 1 guns, 75.4ms\n",
      "\n",
      "0: 384x640 (no detections), 81.1ms\n",
      "\n",
      "0: 384x640 (no detections), 79.0ms\n",
      "\n",
      "0: 384x640 (no detections), 109.0ms\n",
      "\n",
      "0: 384x640 (no detections), 71.1ms\n",
      "[INFO] Done.\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Debounced combined detector:\n",
    " - Knife: Ultralytics YOLO .pt\n",
    " - Gun: OpenCV Haar cascade (debounced + filters)\n",
    "\n",
    "Usage:\n",
    "  python detect_gun_knife_debounced.py --knife-model best.pt --gun-cascade cascade.xml --source data/video.mp4 --save\n",
    "  python detect_gun_knife_debounced.py --source 0\n",
    "\"\"\"\n",
    "\n",
    "import argparse\n",
    "import time\n",
    "import os\n",
    "import cv2\n",
    "import imutils\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# ----------------------------\n",
    "# Arguments\n",
    "# ----------------------------\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--knife-model\", type=str, default=\"best.pt\", help=\"Path to YOLO .pt for knife\")\n",
    "parser.add_argument(\"--gun-cascade\", type=str, default=\"cascade_gun.xml\", help=\"Path to gun Haar cascade XML\")\n",
    "parser.add_argument(\"--source\", type=str, default=\"data/gun4_2.mp4\", help=\"Video source (0 for webcam or path/rtsp)\")\n",
    "parser.add_argument(\"--conf\", type=float, default=0.35, help=\"YOLO confidence threshold\")\n",
    "parser.add_argument(\"--save\", action=\"store_true\", help=\"Save output video to output.mp4\")\n",
    "parser.add_argument(\"--device\", type=str, default=None, help=\"Device for YOLO, e.g. 'cpu' or 'cuda:0'\")\n",
    "args, _ = parser.parse_known_args()\n",
    "\n",
    "# ----------------------------\n",
    "# Configurable tuning params\n",
    "# ----------------------------\n",
    "# Haar cascade params (tune to reduce false positives)\n",
    "HAAR_SCALE = 1.25\n",
    "HAAR_NEIGHBORS = 7\n",
    "HAAR_MIN_SIZE = (40, 40)\n",
    "\n",
    "# Filtering & tracking params\n",
    "MIN_AREA = 900            # min area to accept a detection (px^2)\n",
    "ASPECT_RANGE = (0.25, 2.5)  # acceptable width/height ratio\n",
    "MAX_DIST = 60             # px distance to match detections between frames\n",
    "MIN_HITS = 3              # require at least this many hits before showing a gun box\n",
    "MAX_AGE = 0.6             # seconds to keep a track without updates\n",
    "\n",
    "# ----------------------------\n",
    "# Utility: drawing function\n",
    "# ----------------------------\n",
    "def draw_label(frame, text, box, color=(0, 255, 0), thickness=2):\n",
    "    x1, y1, x2, y2 = box\n",
    "    cv2.rectangle(frame, (x1, y1), (x2, y2), color, thickness)\n",
    "    (tw, th), _ = cv2.getTextSize(text, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 1)\n",
    "    cv2.rectangle(frame, (x1, y1 - th - 6), (x1 + tw + 6, y1), color, -1)\n",
    "    cv2.putText(frame, text, (x1 + 3, y1 - 4), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 1, cv2.LINE_AA)\n",
    "\n",
    "# ----------------------------\n",
    "# Load models\n",
    "# ----------------------------\n",
    "if not os.path.exists(args.knife_model):\n",
    "    raise SystemExit(f\"Knife model not found: {args.knife_model}\")\n",
    "print(\"[INFO] Loading YOLO model for knife:\", args.knife_model)\n",
    "model = YOLO(args.knife_model)\n",
    "yolo_device = args.device if args.device else (\"cuda:0\" if __import__(\"torch\").cuda.is_available() else \"cpu\")\n",
    "print(f\"[INFO] YOLO device: {yolo_device}\")\n",
    "\n",
    "if not os.path.exists(args.gun_cascade):\n",
    "    raise SystemExit(f\"Gun cascade not found: {args.gun_cascade}\")\n",
    "print(\"[INFO] Loading Haar cascade for gun:\", args.gun_cascade)\n",
    "gun_cascade = cv2.CascadeClassifier(args.gun_cascade)\n",
    "\n",
    "# ----------------------------\n",
    "# Open video source\n",
    "# ----------------------------\n",
    "src = int(args.source) if args.source.isdigit() else args.source\n",
    "cap = cv2.VideoCapture(src)\n",
    "if not cap.isOpened():\n",
    "    raise SystemExit(f\"[ERROR] Cannot open source: {args.source}\")\n",
    "\n",
    "W = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH) or 640)\n",
    "H = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT) or 480)\n",
    "FPS = cap.get(cv2.CAP_PROP_FPS) or 25.0\n",
    "\n",
    "writer = None\n",
    "if args.save:\n",
    "    fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "    writer = cv2.VideoWriter(\"output.mp4\", fourcc, FPS, (W, H))\n",
    "    print(\"[INFO] Saving output to output.mp4\")\n",
    "\n",
    "# ----------------------------\n",
    "# Gun tracks storage (persist across frames)\n",
    "# ----------------------------\n",
    "gun_tracks = []  # each track: {'cx','cy','x1','y1','x2','y2','hits','last_seen'}\n",
    "\n",
    "# ----------------------------\n",
    "# Main loop\n",
    "# ----------------------------\n",
    "print(\"[INFO] Starting detection. Press 'q' to quit.\")\n",
    "prev_time = time.time()\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame = imutils.resize(frame, width=800)\n",
    "    cur_time = time.time()\n",
    "\n",
    "    # ---------- Haar: raw detections ----------\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    raw = gun_cascade.detectMultiScale(gray, scaleFactor=HAAR_SCALE,\n",
    "                                       minNeighbors=HAAR_NEIGHBORS, minSize=HAAR_MIN_SIZE)\n",
    "\n",
    "    # ---------- Filter & associate to tracks ----------\n",
    "    new_tracks = []\n",
    "    # process raw boxes\n",
    "    for (x, y, w, h) in raw:\n",
    "        area = w * h\n",
    "        if area < MIN_AREA:\n",
    "            continue\n",
    "        aspect = w / float(h) if h > 0 else 1.0\n",
    "        if not (ASPECT_RANGE[0] <= aspect <= ASPECT_RANGE[1]):\n",
    "            continue\n",
    "        cx, cy = x + w // 2, y + h // 2\n",
    "\n",
    "        matched = False\n",
    "        for t in gun_tracks:\n",
    "            dx = cx - t['cx']; dy = cy - t['cy']\n",
    "            dist = (dx*dx + dy*dy) ** 0.5\n",
    "            if dist <= MAX_DIST:\n",
    "                # update existing track\n",
    "                t['cx'], t['cy'] = cx, cy\n",
    "                t['x1'], t['y1'], t['x2'], t['y2'] = x, y, x + w, y + h\n",
    "                t['hits'] += 1\n",
    "                t['last_seen'] = cur_time\n",
    "                new_tracks.append(t)\n",
    "                matched = True\n",
    "                break\n",
    "        if not matched:\n",
    "            new_t = {'cx': cx, 'cy': cy, 'x1': x, 'y1': y, 'x2': x + w, 'y2': y + h,\n",
    "                     'hits': 1, 'last_seen': cur_time}\n",
    "            new_tracks.append(new_t)\n",
    "\n",
    "    # carry over old tracks not matched but recently seen\n",
    "    for t in gun_tracks:\n",
    "        if (cur_time - t['last_seen']) <= MAX_AGE:\n",
    "            new_tracks.append(t)\n",
    "\n",
    "    # dedupe/merge nearby tracks\n",
    "    merged = []\n",
    "    for t in new_tracks:\n",
    "        found = False\n",
    "        for m in merged:\n",
    "            dx = t['cx'] - m['cx']; dy = t['cy'] - m['cy']\n",
    "            if (dx*dx + dy*dy) ** 0.5 <= (MAX_DIST / 2):\n",
    "                # merge: average center, expand bbox, max hits, update last_seen\n",
    "                m['cx'] = int((m['cx'] + t['cx']) / 2)\n",
    "                m['cy'] = int((m['cy'] + t['cy']) / 2)\n",
    "                m['x1'] = min(m['x1'], t['x1']); m['y1'] = min(m['y1'], t['y1'])\n",
    "                m['x2'] = max(m['x2'], t['x2']); m['y2'] = max(m['y2'], t['y2'])\n",
    "                m['hits'] = max(m['hits'], t['hits'])\n",
    "                m['last_seen'] = max(m['last_seen'], t['last_seen'])\n",
    "                found = True\n",
    "                break\n",
    "        if not found:\n",
    "            merged.append(t)\n",
    "\n",
    "    # keep only recent tracks\n",
    "    gun_tracks = [t for t in merged if (cur_time - t['last_seen']) <= MAX_AGE]\n",
    "\n",
    "    # ---------- Draw persistent gun boxes (only after MIN_HITS) ----------\n",
    "    for t in gun_tracks:\n",
    "        if t['hits'] >= MIN_HITS:\n",
    "            draw_label(frame, \"GUN\", (t['x1'], t['y1'], t['x2'], t['y2']), color=(0, 0, 255))\n",
    "\n",
    "    # ---------- YOLO knife detection (single-frame streaming) ----------\n",
    "    try:\n",
    "        # model(..., stream=True) yields one Results object for this input frame\n",
    "        results = model(frame, conf=args.conf, device=yolo_device, stream=True)\n",
    "        for r in results:\n",
    "            # r.boxes may be empty\n",
    "            if hasattr(r, \"boxes\") and r.boxes is not None and len(r.boxes) > 0:\n",
    "                # convert tensors to numpy if needed\n",
    "                boxes = r.boxes.xyxy.cpu().numpy() if hasattr(r.boxes.xyxy, \"cpu\") else np.array(r.boxes.xyxy)\n",
    "                confs = r.boxes.conf.cpu().numpy() if hasattr(r.boxes.conf, \"cpu\") else np.array(r.boxes.conf)\n",
    "                clss = r.boxes.cls.cpu().numpy() if hasattr(r.boxes.cls, \"cpu\") else np.array(r.boxes.cls)\n",
    "                for box, conf, cls in zip(boxes, confs, clss):\n",
    "                    x1, y1, x2, y2 = map(int, box)\n",
    "                    label = r.names[int(cls)] if hasattr(r, \"names\") else f\"class{int(cls)}\"\n",
    "                    draw_label(frame, f\"{label} {conf:.2f}\", (x1, y1, x2, y2), color=(0, 255, 0))\n",
    "            break\n",
    "    except Exception as e:\n",
    "        # don't spam â€” print once per failure\n",
    "        print(\"[WARN] YOLO exception:\", e)\n",
    "\n",
    "    # ---------- FPS & timestamp ----------\n",
    "    now = time.time()\n",
    "    fps_val = 1.0 / (now - prev_time) if (now - prev_time) > 0 else 0.0\n",
    "    prev_time = now\n",
    "    ts = time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    cv2.putText(frame, f\"{ts}  FPS:{fps_val:.1f}\", (10, frame.shape[0] - 10),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.6, (200, 200, 200), 2)\n",
    "\n",
    "    # ---------- display & save ----------\n",
    "    cv2.imshow(\"Gun+Knife (debounced)\", frame)\n",
    "    if writer:\n",
    "        writer.write(frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "# cleanup\n",
    "cap.release()\n",
    "if writer:\n",
    "    writer.release()\n",
    "cv2.destroyAllWindows()\n",
    "print(\"[INFO] Done.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
